---
layout:     post
title:      "The Beauty of Math(11-15)"
subtitle:   "《数学之美》---吴军"
date:       2018-07-10
author:     "msg"
header-img: "img/post-bg-unix-linux.jpg"
tags:
    - 数学
    - 自然语言处理
    - NLP
---


> 这是我读的第二本书,因为这本书基本上是一本通俗读物,作者将复杂的数学和自然语言处理方面的理论知识,用平易近人的文字,娓娓道来,让不具备相关知识的人,也能轻易的看懂.作者确实很厉害!

### 第11章 如何确定网页和查询的相关性
1) 影响搜索引擎质量的因素，除了用户的点击数据之外，还有一下几点：
> ①完备的索引\\
> ②对网页质量的度量，比如PageRank\\
> ③用户偏好\\
> ④确定一个网页和某个查询的相关性的方法。

2) 度量网页和查询的相关性，有一个简单的办法，就是用各个关键词在网页中出现的词频$TF$；去掉停用词。

3) 需要对汉语中的每一个词语设置一个权重，两个条件：①一个词预测主题的能力越强，权重越大；②停用词权重为0。

4) 假定一个关键词$w$在$D_w$个网页中出现，那么$D_w$越大，$w$的权重越小，反之亦然。

5) $IDF$的概念，最早由剑桥大学斯巴克$\cdot$琼斯提出的，罗宾逊用香农的信息论解释$IDF$，解释对了:所谓$IDF$的概念就是一个指定条件下的关键词概率分布的交叉熵。


### 第12章 有限状态机和动态规划 ---地图与本地搜索的核心技术

1) 基于概率的有限状态机。

2) 图论中一个很常见的问题就是找一个图中给定两个点之间的最短路径，将一个寻找全程最短路线的问题，分解为一个个寻找局部最短路线的小问题，采用动态规划，可以大大降低最短路径的计算复杂度。

### 第13章 Google AK-47的设计者 阿米特$\cdot$辛格博士

一个好的算法，应该像AK-47那样，简单、有效、可靠性好而且容易读懂。

### 第14章 余弦定理和新闻的分类

1) 在一篇文章中，重要的词，$TF-IDF$值就高。对一篇新闻中的所有实词，计算$TF-IDF$值，按对应实词在词汇表中的位置依次排列，就得到一个向量。每一篇都可以对应一个向量，向量每一维度代表每个词对这篇新闻主题的贡献。

2) 自底向上不断合并的方法：
> ① 计算所有新闻之间两两的余弦相似性，把相似性大于一个阈值的新闻合并成一个类。
> ② 把每个小类中所有的新闻作为一个整体，计算小类的特征向量，再计算小类之间两两的余弦相似性，然后合并成大一点的小类。

3) 余弦相似度计算的技巧：
> ① 分母部分不需要重新计算。
> ② 计算两个向量内积时，只需要考虑向量中的非0元素。
> ③ 可以删除虚词。

4) 位置加权：出现在标题中的词比正文中的词重要，出现在文章开头和结尾的词比中间的词重要。

### 第15章 矩阵运算和文本处理中的两个分类问题

1) NLP中，最常见的两个问题是，将文本按主题分类和将词汇表中的字词按意思归类。这两个分类问题可以通过矩阵运算来圆满的一次性的解决。只需要对关联矩阵做一次奇异值分解就可以了。

2) 奇异值分解的优点是能较快的得到结果，适合处理超大规模文本的粗分类，可以先用奇异值分解粗分类，再用计算向量余弦的方法，几次迭代，得到比较精确的结果。