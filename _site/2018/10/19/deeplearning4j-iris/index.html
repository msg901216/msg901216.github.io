<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keywords"  content="">
    <meta name="theme-color" content="">
    
    <title>deeplearning4j-(01)-iris - 学习笔记 | Reading Blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="https://msgi.github.io/2018/10/19/deeplearning4j-iris/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script type="text/javascript" async
src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async>
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        showProcessingMessages: false,
        messageStyle: "none",
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
            inlineMath:  [ ["$", "$"] ],
            displayMath: [ ["$$","$$"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'],
            ignoreClass:"comment-content"
        },
        "HTML-CSS": {
            availableFonts: ["STIX","TeX"],
            showMathMenu: false
        }
    });
    MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
    </script>
    
    <script data-no-instant>
    InstantClick.on('change', function(isInitialLoad){
        if (isInitialLoad === false) {
            if (typeof MathJax !== 'undefined'){
                MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
            }
        }
    });
    InstantClick.init();
    </script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">慢时光的学习笔记</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                    <li>
                        <a href="/about/">About</a>
                    </li>
                    
                    <li>
                        <a href="/tags/">Tags</a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    var __HuxNav__ = {
        close: function(){
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        },
        open: function(){
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }

    // Bind Event
    $toggle.addEventListener('click', function(e){
        if ($navbar.className.indexOf('in') > 0) {
            __HuxNav__.close()
        }else{
            __HuxNav__.open()
        }
    })

    /**
     * Since Fastclick is used to delegate 'touchstart' globally
     * to hack 300ms delay in iOS by performing a fake 'click',
     * Using 'e.stopPropagation' to stop 'touchstart' event from 
     * $toggle/$collapse will break global delegation.
     * 
     * Instead, we use a 'e.target' filter to prevent handler
     * added to document close HuxNav.  
     *
     * Also, we use 'click' instead of 'touchstart' as compromise
     */
    document.addEventListener('click', function(e){
        if(e.target == $toggle) return;
        if(e.target.className == 'icon-bar') return;
        __HuxNav__.close();
    })
</script>


    <!-- Image to hack wechat -->
<!-- <img src="/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/img/posts/01.jpg" width="0" height="0"> -->

<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        position: relative;
        background-image: url('/img/posts/01.jpg')
    }

    
    header.intro-header .header-mask{
        width: 100%;
        height: 100%;
        position: absolute;
        background: rgba(0,0,0, 0.3);
    }
    
</style>
<header class="intro-header" >
    <div class="header-mask"></div>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/#java" title="java">java</a>
                        
                        <a class="tag" href="/tags/#deeplearning4j" title="deeplearning4j">deeplearning4j</a>
                        
                        <a class="tag" href="/tags/#深度学习" title="深度学习">深度学习</a>
                        
                        <a class="tag" href="/tags/#学习" title="学习">学习</a>
                        
                        <a class="tag" href="/tags/#转载" title="转载">转载</a>
                        
                    </div>
                    <h1>deeplearning4j-(01)-iris</h1>
                    
                    
                    <h2 class="subheading">deeplearning4j分类iris数据集</h2>
                    
                    <span class="meta">Posted by msg on October 19, 2018</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <!-- Multi-Lingual -->
                

				<h3 id="introduction">1. Introduction</h3>
<p>In this article, we’ll create a simple neural network with the deeplearning4j (dl4j) library – a modern and powerful tool for machine learning.</p>

<p>Before we get started, not that this guide doesn’t require a profound knowledge of linear algebra, statistics, machine learning theory and lots of other topics necessary for a well-grounded ML engineer.</p>

<h3 id="what-is-deep-learning">2. What is Deep Learning?</h3>
<p>Neural networks are computational models that consist of interconnected layers of nodes.</p>

<p>Nodes are neuron-like processors of numeric data. They take data from their inputs, apply some weights and functions to these data and send the results to outputs. Such network can be trained with some examples of the source data.</p>

<p>Training essentially is saving some numeric state (weights) in the nodes which later affects the computation. Training examples may contain data items with features and certain known classes of these items (for instance, “this set of 16×16 pixels contains a hand-written letter “a”).</p>

<p>After training is finished, a neural network can derive information from new data, even if it has not seen these particular data items before. A well-modeled and well-trained network can recognize images, hand-written letters, speech, process statistical data to produce results for business intelligence, and much more.</p>

<p>Deep neural networks became possible in the recent years, with the advance of high-performance and parallel computing. Such networks differ from simple neural networks in that they consist of multiple intermediate (or hidden) layers. This structure allows networks to process data in a lot more complicated manner (in a recursive, recurrent, convolutional way, etc.), and extract a lot more information from it.</p>

<h3 id="setting-up-the-project">3. Setting Up the Project</h3>
<p>To use the library, we need at least Java 7. Also, due to some native components, it only works with the 64-bit JVM version.</p>

<p>Before starting with the guide, let’s check if requirements are met:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>$ java -version
java version "1.8.0_161"
Java(TM) SE Runtime Environment (build 1.8.0_161-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)
</code></pre>
</div>

<p>First, let’s add the required libraries to our Maven pom.xml file. We’ll extract the version of the library to a property entry (for the latest version of the libraries, check out the Maven Central repository):</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="nt">&lt;properties&gt;</span>
    <span class="nt">&lt;dl4j.version&gt;</span>0.9.1<span class="nt">&lt;/dl4j.version&gt;</span>
<span class="nt">&lt;/properties&gt;</span>
 
<span class="nt">&lt;dependencies&gt;</span>
 
    <span class="nt">&lt;dependency&gt;</span>
        <span class="nt">&lt;groupId&gt;</span>org.nd4j<span class="nt">&lt;/groupId&gt;</span>
        <span class="nt">&lt;artifactId&gt;</span>nd4j-native-platform<span class="nt">&lt;/artifactId&gt;</span>
        <span class="nt">&lt;version&gt;</span>${dl4j.version}<span class="nt">&lt;/version&gt;</span>
    <span class="nt">&lt;/dependency&gt;</span>
 
    <span class="nt">&lt;dependency&gt;</span>
        <span class="nt">&lt;groupId&gt;</span>org.deeplearning4j<span class="nt">&lt;/groupId&gt;</span>
        <span class="nt">&lt;artifactId&gt;</span>deeplearning4j-core<span class="nt">&lt;/artifactId&gt;</span>
        <span class="nt">&lt;version&gt;</span>${dl4j.version}<span class="nt">&lt;/version&gt;</span>
    <span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;/dependencies&gt;</span>
</code></pre>
</div>

<p>Note that nd4j-native-platform dependency is one of the several available implementations.</p>

<p>It relies on native libraries available for many different platforms (macOS, Windows, Linux, Android, etc.). We could also switch the backend to nd4j-cuda-8.0-platform, if we wanted to execute computations on a graphics card that supports CUDA programming model.</p>

<h3 id="preparing-the-data">4. Preparing the Data</h3>
<p>#### 4.1. Preparing the DataSet File<br />
We’ll write the “Hello World” of machine learning — classification of the iris flower data set. This is a set of data that was gathered from the flowers of different species (Iris setosa, Iris versicolor, and Iris virginica).</p>

<p>These species differ in lengths and widths of petals and sepals. It’d be hard to write a precise algorithm that classifies an input data item (i.e., determines to what species does a particular flower belong). But a well-trained neural network can classify it quickly and with little mistakes.</p>

<p>We’re going to use a CSV version of this data, where columns 0..3 contain the different features of the species and column 4 contains the class of the record, or the species, coded with a value 0, 1 or 2:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>5.1,3.5,1.4,0.2,0
4.9,3.0,1.4,0.2,0
4.7,3.2,1.3,0.2,0
…
7.0,3.2,4.7,1.4,1
6.4,3.2,4.5,1.5,1
6.9,3.1,4.9,1.5,1
…

</code></pre>
</div>

<h4 id="vectorizing-and-reading-the-data">4.2. Vectorizing and Reading the Data</h4>
<p>We encode the class with a number because neural networks work with numbers. Transforming real-world data items into series of numbers (vectors) is called vectorization – deeplearning4j uses the datavec library to do this.</p>

<p>First, let’s use this library to input the file with the vectorized data. When creating the CSVRecordReader, we can specify the number of lines to skip (for instance, if the file has a header line) and the separator symbol (in our case a comma):</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">try</span> <span class="o">(</span><span class="n">RecordReader</span> <span class="n">recordReader</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CSVRecordReader</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="sc">','</span><span class="o">))</span> <span class="o">{</span>
    <span class="n">recordReader</span><span class="o">.</span><span class="na">initialize</span><span class="o">(</span><span class="k">new</span> <span class="n">FileSplit</span><span class="o">(</span>
      <span class="k">new</span> <span class="n">ClassPathResource</span><span class="o">(</span><span class="s">"iris.txt"</span><span class="o">).</span><span class="na">getFile</span><span class="o">()));</span>
 
    <span class="c1">// …</span>
<span class="o">}</span>
</code></pre>
</div>

<p>To iterate over the records, we can use any of the multiple implementations of the DataSetIterator interface. The datasets can be quite massive, and the ability to page or cache the values could come in handy.</p>

<p>But our small dataset contains only 150 records, so let’s read all the data into memory at once with a call of iterator.next().</p>

<p>We also specify the index of the class column which in our case is the same as feature count (4) and the total number of classes (3).</p>

<p>Also, note that we need to shuffle the dataset to get rid of the class ordering in the original file.</p>

<p>We specify a constant random seed (42) instead of the default System.currentTimeMillis() call so that the results of the shuffling would always be the same. This allows us to get stable results each time we will run the program:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">DataSetIterator</span> <span class="n">iterator</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RecordReaderDataSetIterator</span><span class="o">(</span>
  <span class="n">recordReader</span><span class="o">,</span> <span class="mi">150</span><span class="o">,</span> <span class="n">FEATURES_COUNT</span><span class="o">,</span> <span class="n">CLASSES_COUNT</span><span class="o">);</span>
<span class="n">DataSet</span> <span class="n">allData</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="na">next</span><span class="o">();</span>
<span class="n">allData</span><span class="o">.</span><span class="na">shuffle</span><span class="o">(</span><span class="mi">42</span><span class="o">);</span>
</code></pre>
</div>

<h4 id="normalizing-and-splitting">4.3. Normalizing and Splitting</h4>
<p>Another thing we should do with the data before training is to normalize it. The normalization is a two-phase process:</p>

<p>gathering of some statistics about the data (fit)<br />
changing (transform) the data in some way to make it uniform<br />
Normalization may differ for different types of data.</p>

<p>For instance, if we want to process images of various sizes, we should first collect the size statistics and then scale the images to a uniform size.</p>

<p>But for numbers, normalization usually means transforming them into a so-called normal distribution. The NormalizerStandardize class can help us with that:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">DataNormalization</span> <span class="n">normalizer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">NormalizerStandardize</span><span class="o">();</span>
<span class="n">normalizer</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">allData</span><span class="o">);</span>
<span class="n">normalizer</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">allData</span><span class="o">);</span>
</code></pre>
</div>

<p>Now that the data is prepared, we need to split the set into two parts.</p>

<p>The first part will be used in a training session. We’ll use the second part of the data (which the network would not see at all) to test the trained network.</p>

<p>This would allow us to verify that the classification works correctly. We will take 65% of the data (0.65) for the training and leave the rest 35% for the testing:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">SplitTestAndTrain</span> <span class="n">testAndTrain</span> <span class="o">=</span> <span class="n">allData</span><span class="o">.</span><span class="na">splitTestAndTrain</span><span class="o">(</span><span class="mf">0.65</span><span class="o">);</span>
<span class="n">DataSet</span> <span class="n">trainingData</span> <span class="o">=</span> <span class="n">testAndTrain</span><span class="o">.</span><span class="na">getTrain</span><span class="o">();</span>
<span class="n">DataSet</span> <span class="n">testData</span> <span class="o">=</span> <span class="n">testAndTrain</span><span class="o">.</span><span class="na">getTest</span><span class="o">();</span>
</code></pre>
</div>

<h3 id="preparing-the-network-configuration">5. Preparing the Network Configuration</h3>
<p>#### 5.1. Fluent Configuration Builder<br />
Now we can build a configuration of our network with a fancy fluent builder:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">MultiLayerConfiguration</span> <span class="n">configuration</span> 
  <span class="o">=</span> <span class="k">new</span> <span class="n">NeuralNetConfiguration</span><span class="o">.</span><span class="na">Builder</span><span class="o">()</span>
    <span class="o">.</span><span class="na">iterations</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
    <span class="o">.</span><span class="na">activation</span><span class="o">(</span><span class="n">Activation</span><span class="o">.</span><span class="na">TANH</span><span class="o">)</span>
    <span class="o">.</span><span class="na">weightInit</span><span class="o">(</span><span class="n">WeightInit</span><span class="o">.</span><span class="na">XAVIER</span><span class="o">)</span>
    <span class="o">.</span><span class="na">learningRate</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>
    <span class="o">.</span><span class="na">regularization</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="na">l2</span><span class="o">(</span><span class="mf">0.0001</span><span class="o">)</span>
    <span class="o">.</span><span class="na">list</span><span class="o">()</span>
    <span class="o">.</span><span class="na">layer</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="k">new</span> <span class="n">DenseLayer</span><span class="o">.</span><span class="na">Builder</span><span class="o">().</span><span class="na">nIn</span><span class="o">(</span><span class="n">FEATURES_COUNT</span><span class="o">).</span><span class="na">nOut</span><span class="o">(</span><span class="mi">3</span><span class="o">).</span><span class="na">build</span><span class="o">())</span>
    <span class="o">.</span><span class="na">layer</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="k">new</span> <span class="n">DenseLayer</span><span class="o">.</span><span class="na">Builder</span><span class="o">().</span><span class="na">nIn</span><span class="o">(</span><span class="mi">3</span><span class="o">).</span><span class="na">nOut</span><span class="o">(</span><span class="mi">3</span><span class="o">).</span><span class="na">build</span><span class="o">())</span>
    <span class="o">.</span><span class="na">layer</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span> <span class="k">new</span> <span class="n">OutputLayer</span><span class="o">.</span><span class="na">Builder</span><span class="o">(</span>
      <span class="n">LossFunctions</span><span class="o">.</span><span class="na">LossFunction</span><span class="o">.</span><span class="na">NEGATIVELOGLIKELIHOOD</span><span class="o">)</span>
        <span class="o">.</span><span class="na">activation</span><span class="o">(</span><span class="n">Activation</span><span class="o">.</span><span class="na">SOFTMAX</span><span class="o">)</span>
        <span class="o">.</span><span class="na">nIn</span><span class="o">(</span><span class="mi">3</span><span class="o">).</span><span class="na">nOut</span><span class="o">(</span><span class="n">CLASSES_COUNT</span><span class="o">).</span><span class="na">build</span><span class="o">())</span>
    <span class="o">.</span><span class="na">backprop</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="na">pretrain</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="na">build</span><span class="o">();</span>
</code></pre>
</div>

<p>Even with this simplified fluent way of building a network model, there’s a lot to digest and a lot of parameters to tweak. Let’s break this model down.</p>

<h4 id="setting-network-parameters">5.2. Setting Network Parameters</h4>
<p>The iterations() builder method specifies the number of optimization iterations.</p>

<p>The iterative optimization means performing multiple passes on the training set until the network converges to a good result.</p>

<p>Usually, when training on real and large datasets, we use multiple epochs (complete passes of data through the network) and one iteration for each epoch. But since our initial dataset is minimal, we’ll use one epoch and multiple iterations.</p>

<p>The activation() is a function that runs inside a node to determine its output.</p>

<p>The simplest activation function would be linear f(x) = x. But it turns out that only non-linear functions allow networks to solve complex tasks by using a few nodes.</p>

<p>There are lots of different activation functions available which we can look up in the org.nd4j.linalg.activations.Activation enum. We could also write our activation function if needed. But we’ll use the provided hyperbolic tangent (tanh) function.</p>

<p>The weightInit() method specifies one of the many ways to set up the initial weights for the network. Correct initial weights can profoundly affect the results of the training. Without going too much into the math, let’s set it to a form of Gaussian distribution (WeightInit.XAVIER), as this is usually a good choice for a start.</p>

<p>All other weight initialization methods can be looked up in the org.deeplearning4j.nn.weights.WeightInit enum.</p>

<p>Learning rate is a crucial parameter that profoundly affects the ability of the network to learn.</p>

<p>We could spend a lot of time tweaking this parameter in a more complex case. But for our simple task, we’ll use a pretty significant value of 0.1 and set it up with the learningRate() builder method.</p>

<p>One of the problems with training neural networks is a case of overfitting when a network “memorizes” the training data.</p>

<p>This happens when the network sets excessively high weights for the training data and produces bad results on any other data.</p>

<p>To solve this issue, we’re going to set up l2 regularization with the line .regularization(true).l2(0.0001). Regularization “penalizes” the network for too large weights and prevents overfitting.</p>

<h4 id="building-network-layers">5.3. Building Network Layers</h4>
<p>Next, we create a network of dense (also known as fully connect) layers.</p>

<p>The first layer should contain the same amount of nodes as the columns in the training data (4).</p>

<p>The second dense layer will contain three nodes. This is the value we can variate, but the number of outputs in the previous layer has to be the same.</p>

<p>The final output layer should contain the number of nodes matching the number of classes (3). The structure of the network is shown in the picture:</p>

<p>After successful training, we’ll have a network that receives four values via its inputs and sends a signal to one of its three outputs. This is a simple classifier.</p>

<p>Finally, to finish building the network, we set up back propagation (one of the most effective training methods) and disable pre-training with the line .backprop(true).pretrain(false).</p>

<h3 id="creating-and-training-a-network">6. Creating and Training a Network</h3>
<p>Now let’s create a neural network from the configuration, initialize and run it:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">MultiLayerNetwork</span> <span class="n">model</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MultiLayerNetwork</span><span class="o">(</span><span class="n">configuration</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">init</span><span class="o">();</span>
<span class="n">model</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">);</span>
</code></pre>
</div>

<p>Now we can test the trained model by using the rest of the dataset and verify the results with evaluation metrics for three classes:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">INDArray</span> <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="n">testData</span><span class="o">.</span><span class="na">getFeatureMatrix</span><span class="o">());</span>
<span class="n">Evaluation</span> <span class="n">eval</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Evaluation</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>
<span class="n">eval</span><span class="o">.</span><span class="na">eval</span><span class="o">(</span><span class="n">testData</span><span class="o">.</span><span class="na">getLabels</span><span class="o">(),</span> <span class="n">output</span><span class="o">);</span>
</code></pre>
</div>

<p>If we now print out the eval.stats(), we’ll see that our network is pretty good at classifying iris flowers, although it did mistake class 1 for class 2 three times.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Examples labeled as 0 classified by model as 0: 19 times
Examples labeled as 1 classified by model as 1: 16 times
Examples labeled as 1 classified by model as 2: 3 times
Examples labeled as 2 classified by model as 2: 15 times
 
==========================Scores========================================
# of classes: 3
Accuracy: 0.9434
Precision: 0.9444
Recall: 0.9474
F1 Score: 0.9411
Precision, recall &amp; F1: macro-averaged (equally weighted avg. of 3 classes)
========================================================================
</code></pre>
</div>

<p>The fluent configuration builder allows us to add or modify layers of the network quickly, or tweak some other parameters to see if our model can be improved.</p>

<h3 id="conclusion">7. Conclusion</h3>
<p>In this article, we’ve built a simple yet powerful neural network by using the deeplearning4j library.</p>

<p>As always, the source code for the article is available over on GitHub.</p>



                <hr style="visibility: hidden;">

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2018/10/11/fasttext/" data-toggle="tooltip" data-placement="top" title="FastText">
                        Previous<br>
                        <span>FastText</span>
                        </a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2018/12/02/notes-java/" data-toggle="tooltip" data-placement="top" title="java的学习笔记">
                        Next<br>
                        <span>java的学习笔记</span>
                        </a>
                    </li>
                    
                </ul>


                

                
            </div>  

    <!-- Side Catalog Container -->
        
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
        

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
        				
                            
        				
                            
        				
                            
                				<a href="/tags/#NLP" title="NLP" rel="9">
                                    NLP
                                </a>
                            
        				
                            
        				
                            
        				
                            
                				<a href="/tags/#数学" title="数学" rel="6">
                                    数学
                                </a>
                            
        				
                            
                				<a href="/tags/#自然语言处理" title="自然语言处理" rel="10">
                                    自然语言处理
                                </a>
                            
        				
                            
                				<a href="/tags/#励志" title="励志" rel="5">
                                    励志
                                </a>
                            
        				
                            
        				
                            
                				<a href="/tags/#转载" title="转载" rel="23">
                                    转载
                                </a>
                            
        				
                            
        				
                            
                				<a href="/tags/#学习" title="学习" rel="25">
                                    学习
                                </a>
                            
        				
                            
                				<a href="/tags/#java" title="java" rel="7">
                                    java
                                </a>
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
                				<a href="/tags/#笔记" title="笔记" rel="3">
                                    笔记
                                </a>
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
                				<a href="/tags/#ubuntu" title="ubuntu" rel="5">
                                    ubuntu
                                </a>
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
        			</div>
                </section>
                

                <!-- Friends Blog -->
                
            </div>
        </div>
    </div>
</article>









<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'always',
          placement: 'right',
          icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    
                    

                    <!-- add Weibo, Zhihu by Hux, add target = "_blank" to <a> by Hux -->
                    
                    


                    
                    
                    
                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; 慢时光的学习笔记 2019
                    <br>
                    Theme by <a href="http://huangxuan.me">Hux</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=huxpro&repo=huxpro.github.io&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<!-- Currently, only navbar scroll-down effect at desktop still depends on this -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>

<!-- Service Worker -->


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async('/js/jquery.tagcloud.js',function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->



<!-- Baidu Tongji -->



<!-- Side Catalog -->

<script type="text/javascript">
    function generateCatalog (selector) {

        // interop with multilangual 
        if ('' == 'true') {
            _containerSelector = 'div.post-container.active'
        } else {
            _containerSelector = 'div.post-container'
        }

        // init
        var P = $(_containerSelector),a,n,t,l,i,c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        // clean
        $(selector).html('')

        // appending
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#"+$(this).prop('id');
            t = $(this).text();
            c = $('<a href="'+i+'" rel="nofollow">'+t+'</a>');
            l = $('<li class="'+n+'_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function(e){
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Hux to support padding
     */
    async("/js/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>



<!-- Multi-Lingual -->




<!-- Image to hack wechat -->
<img src="/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
