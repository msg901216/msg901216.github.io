<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keywords"  content="">
    <meta name="theme-color" content="">
    
    <title>How to Create an LSTM Recurrent Neural Network Using DL4J - 学习笔记 | Reading Blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="http://localhost:4000/2018/09/21/How-to-Create-an-LSTM-Recurrent-Neural-Network-Using-DL4J/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script type="text/javascript" async
src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async>
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        showProcessingMessages: false,
        messageStyle: "none",
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
            inlineMath:  [ ["$", "$"] ],
            displayMath: [ ["$$","$$"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'],
            ignoreClass:"comment-content"
        },
        "HTML-CSS": {
            availableFonts: ["STIX","TeX"],
            showMathMenu: false
        }
    });
    MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
    </script>
    
    <script data-no-instant>
    InstantClick.on('change', function(isInitialLoad){
        if (isInitialLoad === false) {
            if (typeof MathJax !== 'undefined'){
                MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
            }
        }
    });
    InstantClick.init();
    </script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">慢时光的学习笔记</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                    <li>
                        <a href="/about/">About</a>
                    </li>
                    
                    <li>
                        <a href="/tags/">Tags</a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    var __HuxNav__ = {
        close: function(){
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        },
        open: function(){
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }

    // Bind Event
    $toggle.addEventListener('click', function(e){
        if ($navbar.className.indexOf('in') > 0) {
            __HuxNav__.close()
        }else{
            __HuxNav__.open()
        }
    })

    /**
     * Since Fastclick is used to delegate 'touchstart' globally
     * to hack 300ms delay in iOS by performing a fake 'click',
     * Using 'e.stopPropagation' to stop 'touchstart' event from 
     * $toggle/$collapse will break global delegation.
     * 
     * Instead, we use a 'e.target' filter to prevent handler
     * added to document close HuxNav.  
     *
     * Also, we use 'click' instead of 'touchstart' as compromise
     */
    document.addEventListener('click', function(e){
        if(e.target == $toggle) return;
        if(e.target.className == 'icon-bar') return;
        __HuxNav__.close();
    })
</script>


    <!-- Image to hack wechat -->
<!-- <img src="/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/img/posts/01.jpg" width="0" height="0"> -->

<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        position: relative;
        background-image: url('/img/posts/01.jpg')
    }

    
    header.intro-header .header-mask{
        width: 100%;
        height: 100%;
        position: absolute;
        background: rgba(0,0,0, 0.3);
    }
    
</style>
<header class="intro-header" >
    <div class="header-mask"></div>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/#java" title="java">java</a>
                        
                        <a class="tag" href="/tags/#学习" title="学习">学习</a>
                        
                        <a class="tag" href="/tags/#自然语言处理" title="自然语言处理">自然语言处理</a>
                        
                        <a class="tag" href="/tags/#LSTM" title="LSTM">LSTM</a>
                        
                        <a class="tag" href="/tags/#deeplearning4j" title="deeplearning4j">deeplearning4j</a>
                        
                        <a class="tag" href="/tags/#转载" title="转载">转载</a>
                        
                    </div>
                    <h1>How to Create an LSTM Recurrent Neural Network Using DL4J</h1>
                    
                    
                    <h2 class="subheading">用deeplearning4j创建lstm生成一定风格的句子</h2>
                    
                    <span class="meta">Posted by msg on September 21, 2018</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <!-- Multi-Lingual -->
                

				<p>Long short-term memory recurrent neural networks, or LSTM RNNs for short, are neural networks that can memorize and regurgitate sequential data. They’ve become very popular these days, primarly because they can be used to create bots that can generate articles, stories, music, poems, screenplays - you name it! How? Well, its because a lot of things humans do involve sequences.</p>

<p>To make things clearer, let me give you a few examples. An LSTM can be trained on a novel to generate sentences that look very similar to those present in the novel. If you train it with multiple novels written by the same author, the LSTM will start sounding like the author. Similarly, an LSTM trained using a collection of songs that belong to a specific genre of music will be able to generate “songs” that belong to the same genre. I hope you get the idea.</p>

<p>In this tutorial, I’ll show you how to use Deeplearning4J to create an LSTM that can generate sentences that are similar to those written by the prolific 19th century author Emma Leslie. We’ll be using her novel Hayslope Grange as our training data, so, before we begin, I suggest you download the novel as plain text and store it somewhere on your computer.</p>

<h3 id="read-the-novel">Read the Novel</h3>

<p>The first thing you need to do is, of course, convert the text of the novel into a string you can use in your program. The easiest way to do so is to use the <strong><em>IOUtils.toString()</em></strong> method, which is available in the Apache Commons IO library.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">String</span> <span class="n">inputData</span> <span class="o">=</span> <span class="n">IOUtils</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="k">new</span> <span class="n">FileInputStream</span><span class="o">(</span><span class="s">"/tmp/temp.txt"</span><span class="o">),</span> <span class="s">"UTF-8"</span><span class="o">);</span>
</code></pre></div></div>

<p>You are free to use all the text that’s available in the novel. I, however, in order to speed things up, will be using only the first 50000 characters.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputData</span> <span class="o">=</span> <span class="n">inputData</span><span class="o">.</span><span class="na">substring</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">50000</span><span class="o">);</span>
</code></pre></div></div>

<h3 id="design-the-lstm-neural-network">Design the LSTM Neural Network</h3>

<p>Our neural network shall have an input LSTM layer, a hidden layer, and an output RNN layer. How many neurons should be present in these layers? Well, that depends on how many different characters your network can handle.</p>

<p>For now, let’s say our network can handle all the letters of the English alphabet, in both uppercase and lowercase, all the digits from 0-9, and a few special characters.</p>

<p>The following string has all the characters I will be using:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">String</span> <span class="n">validCharacters</span> <span class="o">=</span> 
        <span class="s">"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz1234567890\"\n',.?;()[]{}:!- "</span><span class="o">;</span>
</code></pre></div></div>

<p>Our input and output layers must have one neuron for each character that’s present in the above string. As for the hidden layer, I’ll use 30 neurons. You are free to change that number.</p>

<p>To create an input LSTM layer with DL4J, you must use the GravesLSTM class. Similarly, to create an output RNN layer, you must use the RnnOutputLayer class. While creating these layers, you must remember to specify the activation functions they should use. For best results, using TANH for the input layer and SOFTMAX for the output layer is recommended.</p>

<p>Accordingly, add the following code:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">GravesLSTM</span><span class="o">.</span><span class="na">Builder</span> <span class="n">lstmBuilder</span> <span class="o">=</span> <span class="k">new</span> <span class="n">GravesLSTM</span><span class="o">.</span><span class="na">Builder</span><span class="o">();</span>
<span class="n">lstmBuilder</span><span class="o">.</span><span class="na">activation</span><span class="o">(</span><span class="n">Activation</span><span class="o">.</span><span class="na">TANH</span><span class="o">);</span>
<span class="n">lstmBuilder</span><span class="o">.</span><span class="na">nIn</span><span class="o">(</span><span class="n">validCharacters</span><span class="o">.</span><span class="na">length</span><span class="o">());</span>
<span class="n">lstmBuilder</span><span class="o">.</span><span class="na">nOut</span><span class="o">(</span><span class="mi">30</span><span class="o">);</span> <span class="c1">// Hidden</span>
<span class="n">GravesLSTM</span> <span class="n">inputLayer</span> <span class="o">=</span> <span class="n">lstmBuilder</span><span class="o">.</span><span class="na">build</span><span class="o">();</span>

<span class="n">RnnOutputLayer</span><span class="o">.</span><span class="na">Builder</span> <span class="n">outputBuilder</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RnnOutputLayer</span><span class="o">.</span><span class="na">Builder</span><span class="o">();</span>
<span class="n">outputBuilder</span><span class="o">.</span><span class="na">lossFunction</span><span class="o">(</span><span class="n">LossFunctions</span><span class="o">.</span><span class="na">LossFunction</span><span class="o">.</span><span class="na">MSE</span><span class="o">);</span>
<span class="n">outputBuilder</span><span class="o">.</span><span class="na">activation</span><span class="o">(</span><span class="n">Activation</span><span class="o">.</span><span class="na">SOFTMAX</span><span class="o">);</span>
<span class="n">outputBuilder</span><span class="o">.</span><span class="na">nIn</span><span class="o">(</span><span class="mi">30</span><span class="o">);</span> <span class="c1">// Hidden</span>
<span class="n">outputBuilder</span><span class="o">.</span><span class="na">nOut</span><span class="o">(</span><span class="n">validCharacters</span><span class="o">.</span><span class="na">length</span><span class="o">());</span>
<span class="n">RnnOutputLayer</span> <span class="n">outputLayer</span> <span class="o">=</span> <span class="n">outputBuilder</span><span class="o">.</span><span class="na">build</span><span class="o">();</span>
</code></pre></div></div>

<p>Well, now that our neuron layers are ready, we can use them to create a MultiLayerNetwork object. You must, however, also create a NeuralNetConfiguration.Builder in order to configure the network. As always, during the configuration, you must specify details such as which optimization algorithm and updater to use, how to initialize the weights, and what the learning rate should be.</p>

<p>Here’s the configuration I used:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">NeuralNetConfiguration</span><span class="o">.</span><span class="na">Builder</span> <span class="n">nnBuilder</span> <span class="o">=</span> <span class="k">new</span> <span class="n">NeuralNetConfiguration</span><span class="o">.</span><span class="na">Builder</span><span class="o">();</span>
<span class="n">nnBuilder</span><span class="o">.</span><span class="na">optimizationAlgo</span><span class="o">(</span><span class="n">OptimizationAlgorithm</span><span class="o">.</span><span class="na">STOCHASTIC_GRADIENT_DESCENT</span><span class="o">);</span>
<span class="n">nnBuilder</span><span class="o">.</span><span class="na">updater</span><span class="o">(</span><span class="n">Updater</span><span class="o">.</span><span class="na">ADAM</span><span class="o">);</span>
<span class="n">nnBuilder</span><span class="o">.</span><span class="na">weightInit</span><span class="o">(</span><span class="n">WeightInit</span><span class="o">.</span><span class="na">XAVIER</span><span class="o">);</span>
<span class="n">nnBuilder</span><span class="o">.</span><span class="na">learningRate</span><span class="o">(</span><span class="mf">0.01</span><span class="o">);</span>
<span class="n">nnBuilder</span><span class="o">.</span><span class="na">miniBatch</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>

<span class="n">MultiLayerNetwork</span> <span class="n">network</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MultiLayerNetwork</span><span class="o">(</span>
            <span class="n">nnBuilder</span><span class="o">.</span><span class="na">list</span><span class="o">().</span><span class="na">layer</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="n">inputLayer</span><span class="o">)</span>
                    <span class="o">.</span><span class="na">layer</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">outputLayer</span><span class="o">)</span>
                    <span class="o">.</span><span class="na">backprop</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="na">pretrain</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
                    <span class="o">.</span><span class="na">build</span><span class="o">());</span>

<span class="n">network</span><span class="o">.</span><span class="na">init</span><span class="o">();</span>
</code></pre></div></div>

<h3 id="create-training-data">Create Training Data</h3>

<p>As you might already know, DL4J expects you to place all your training data inside INDArray objects. That means, we must now create two INDArray objects: one for the input values and one for the expected output values, or labels.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">INDArray</span> <span class="n">inputArray</span> <span class="o">=</span> <span class="n">Nd4j</span><span class="o">.</span><span class="na">zeros</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">inputLayer</span><span class="o">.</span><span class="na">getNIn</span><span class="o">(),</span> <span class="n">inputData</span><span class="o">.</span><span class="na">length</span><span class="o">());</span>
<span class="n">INDArray</span> <span class="n">inputLabels</span> <span class="o">=</span> <span class="n">Nd4j</span><span class="o">.</span><span class="na">zeros</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">outputLayer</span><span class="o">.</span><span class="na">getNOut</span><span class="o">(),</span> <span class="n">inputData</span><span class="o">.</span><span class="na">length</span><span class="o">());</span>
</code></pre></div></div>

<p>While using an LSTM, the label for an input value is nothing but the next input value. For example, if your training data is the string “abc”, for the input value “a”, the label will be “b”. Similarly, for the input value “b”, the label will be “c”.</p>

<p>Keeping that in mind, you can populate the INDArray objects using the following code:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span><span class="o">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="o">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">inputData</span><span class="o">.</span><span class="na">length</span><span class="o">()</span> <span class="o">-</span> <span class="mi">1</span><span class="o">;</span><span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
    <span class="kt">int</span> <span class="n">positionInValidCharacters1</span> <span class="o">=</span> <span class="n">validCharacters</span><span class="o">.</span><span class="na">indexOf</span><span class="o">(</span><span class="n">inputData</span><span class="o">.</span><span class="na">charAt</span><span class="o">(</span><span class="n">i</span><span class="o">));</span>
    <span class="n">inputArray</span><span class="o">.</span><span class="na">putScalar</span><span class="o">(</span><span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">0</span><span class="o">,</span> <span class="n">positionInValidCharacters1</span><span class="o">,</span> <span class="n">i</span><span class="o">},</span> <span class="mi">1</span><span class="o">);</span>

    <span class="kt">int</span> <span class="n">positionInValidCharacters2</span> <span class="o">=</span> <span class="n">validCharacters</span><span class="o">.</span><span class="na">indexOf</span><span class="o">(</span><span class="n">inputData</span><span class="o">.</span><span class="na">charAt</span><span class="o">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">));</span>
    <span class="n">inputLabels</span><span class="o">.</span><span class="na">putScalar</span><span class="o">(</span><span class="k">new</span> <span class="kt">int</span><span class="o">[]{</span><span class="mi">0</span><span class="o">,</span> <span class="n">positionInValidCharacters2</span><span class="o">,</span> <span class="n">i</span><span class="o">},</span> <span class="mi">1</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>Using the INDArray objects, you can now create a DataSet that can be directly used by your neural network.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DataSet</span> <span class="n">dataSet</span> <span class="o">=</span> <span class="k">new</span> <span class="n">DataSet</span><span class="o">(</span><span class="n">inputArray</span><span class="o">,</span> <span class="n">inputLabels</span><span class="o">);</span>
</code></pre></div></div>

<h3 id="training-the-neural-network">Training the Neural Network</h3>

<p>At this point, all you need to do is call the fit() method and pass the data set to the neural network. However, trying to fit the data set just once is usually not enough. You must fit it several times before the neural network becomes accurate. I suggest you do it a thousand times at least.</p>

<p>Obviously, fitting the data a thousand times is going to take quite a long time. To be able to see the intermediate results the network generates for every iteration, you can pass test data to the network after each call to the fit() method.</p>

<p>The test data, of course, will be another INDArray object whose size is equal to the size of the network’s input layer. It will contain the index of just one character, which will also be the first character of the network’s generated text.</p>

<p>Using that character, our LSTM will generate a new character. By passing that generated character back to the LSTM as the next test data, you can generate another character. By repeating these steps again and again, you can generate strings that are arbitrarily long.</p>

<p>The following code shows you how to generate a string that’s 200 characters long for every iteration:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span><span class="o">(</span><span class="kt">int</span> <span class="n">z</span><span class="o">=</span><span class="mi">0</span><span class="o">;</span><span class="n">z</span><span class="o">&lt;</span><span class="mi">1000</span><span class="o">;</span><span class="n">z</span><span class="o">++)</span> <span class="o">{</span>
    <span class="n">network</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataSet</span><span class="o">);</span>

    <span class="n">INDArray</span> <span class="n">testInputArray</span> <span class="o">=</span> <span class="n">Nd4j</span><span class="o">.</span><span class="na">zeros</span><span class="o">(</span><span class="n">inputLayer</span><span class="o">.</span><span class="na">getNIn</span><span class="o">());</span>
    <span class="n">testInputArray</span><span class="o">.</span><span class="na">putScalar</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">);</span>

    <span class="n">network</span><span class="o">.</span><span class="na">rnnClearPreviousState</span><span class="o">();</span>
    <span class="n">String</span> <span class="n">output</span> <span class="o">=</span> <span class="s">""</span><span class="o">;</span>
    <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">200</span><span class="o">;</span> <span class="n">k</span><span class="o">++)</span> <span class="o">{</span>
        <span class="n">INDArray</span> <span class="n">outputArray</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="na">rnnTimeStep</span><span class="o">(</span><span class="n">testInputArray</span><span class="o">);</span>
        <span class="kt">double</span> <span class="n">maxPrediction</span> <span class="o">=</span> <span class="n">Double</span><span class="o">.</span><span class="na">MIN_VALUE</span><span class="o">;</span>
        <span class="kt">int</span> <span class="n">maxPredictionIndex</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">;</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">validCharacters</span><span class="o">.</span><span class="na">length</span><span class="o">();</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">maxPrediction</span> <span class="o">&lt;</span> <span class="n">outputArray</span><span class="o">.</span><span class="na">getDouble</span><span class="o">(</span><span class="n">i</span><span class="o">))</span> <span class="o">{</span>
                <span class="n">maxPrediction</span> <span class="o">=</span> <span class="n">outputArray</span><span class="o">.</span><span class="na">getDouble</span><span class="o">(</span><span class="n">i</span><span class="o">);</span>
                <span class="n">maxPredictionIndex</span> <span class="o">=</span> <span class="n">i</span><span class="o">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="c1">// Concatenate generated character</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="n">validCharacters</span><span class="o">.</span><span class="na">charAt</span><span class="o">(</span><span class="n">maxPredictionIndex</span><span class="o">);</span>
        <span class="n">testInputArray</span> <span class="o">=</span> <span class="n">Nd4j</span><span class="o">.</span><span class="na">zeros</span><span class="o">(</span><span class="n">inputLayer</span><span class="o">.</span><span class="na">getNIn</span><span class="o">());</span>
        <span class="n">testInputArray</span><span class="o">.</span><span class="na">putScalar</span><span class="o">(</span><span class="n">maxPredictionIndex</span><span class="o">,</span> <span class="mi">1</span><span class="o">);</span>
    <span class="o">}</span>
    <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">z</span> <span class="o">+</span> <span class="s">" &gt; A"</span> <span class="o">+</span> <span class="n">output</span> <span class="o">+</span> <span class="s">"\n----------\n"</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div></div>

<p>As you can see in the above code, we are finding the output neuron with the highest value and using it to determine the next character. Also note that you must always remember to call the rnnClearPreviousState() method in every iteration.</p>

<p>And that’s all there is to creating an LSTM. Go ahead and run the program to see it generate sentences and paragraphs that are eerily similar to valid English prose.</p>

<p>Here are some paragraphs my LSTM generated after being trained for nearly an hour:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># At iteration 400
At as tebeer spws sowingg yeay ans tulm uulmr, and ane smel-nolng one loomyeang one loo loon one loor and the Harlond mayeld hat could make
the far-lnold years cfer
he s had make
so furils of the reang

# At iteration 600
At arss the sof mangsming dayd anys civme dard any of
the darmyeand coumy on ofeendmeeand fol of
the dere deing wmilendewe of
ftw ongling going of Haknf
the farm-loket could have wondeere thamen-folk f

# At iteration 800
At arslas going gayeads sfmiry as after s fmeras and anys names and song and anlmaso off
the ands of
thad soingl, soing amelas of
the formesars civil were of
England, and noul Haaldeha have wondered it

# At iteration 1000
As was sweet spring yaays summer, and any one of Hayslope any one sumirer all seee lone loo long, now so full of the promise of earl that the farm could have wondered smiling England of farm-labourers
As you can see, the paragraphs still contain quite a lot of jibberish. By increasing the number of iterations, and by using more of the novel, you can get better results.
</code></pre></div></div>

<h3 id="conclusion">Conclusion</h3>

<p>You now know how to create a simple LSTM using DeepLearning4J. Although we created a character-based LSTM, it is possible to create LSTMs that are word based, which will generate sentences that are more natural. Doing so, however, would definitely be slightly more complex.</p>


                <hr style="visibility: hidden;">

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2018/09/20/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%E5%8C%85/" data-toggle="tooltip" data-placement="top" title="NLP tools">
                        Previous<br>
                        <span>NLP tools</span>
                        </a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2018/10/05/Thymeleaf/" data-toggle="tooltip" data-placement="top" title="Thymeleaf">
                        Next<br>
                        <span>Thymeleaf</span>
                        </a>
                    </li>
                    
                </ul>


                

                
            </div>  

    <!-- Side Catalog Container -->
        
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
        

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
        				
                            
        				
                            
        				
                            
                				<a href="/tags/#NLP" title="NLP" rel="9">
                                    NLP
                                </a>
                            
        				
                            
        				
                            
        				
                            
                				<a href="/tags/#数学" title="数学" rel="6">
                                    数学
                                </a>
                            
        				
                            
                				<a href="/tags/#自然语言处理" title="自然语言处理" rel="10">
                                    自然语言处理
                                </a>
                            
        				
                            
                				<a href="/tags/#励志" title="励志" rel="5">
                                    励志
                                </a>
                            
        				
                            
        				
                            
                				<a href="/tags/#转载" title="转载" rel="23">
                                    转载
                                </a>
                            
        				
                            
        				
                            
                				<a href="/tags/#学习" title="学习" rel="25">
                                    学习
                                </a>
                            
        				
                            
                				<a href="/tags/#java" title="java" rel="7">
                                    java
                                </a>
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
                				<a href="/tags/#笔记" title="笔记" rel="3">
                                    笔记
                                </a>
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
                				<a href="/tags/#ubuntu" title="ubuntu" rel="5">
                                    ubuntu
                                </a>
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
        			</div>
                </section>
                

                <!-- Friends Blog -->
                
            </div>
        </div>
    </div>
</article>









<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'always',
          placement: 'right',
          icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    
                    

                    <!-- add Weibo, Zhihu by Hux, add target = "_blank" to <a> by Hux -->
                    
                    


                    
                    
                    
                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; 慢时光的学习笔记 2019
                    <br>
                    Theme by <a href="http://huangxuan.me">Hux</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=huxpro&repo=huxpro.github.io&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<!-- Currently, only navbar scroll-down effect at desktop still depends on this -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>

<!-- Service Worker -->


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async('/js/jquery.tagcloud.js',function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->



<!-- Baidu Tongji -->



<!-- Side Catalog -->

<script type="text/javascript">
    function generateCatalog (selector) {

        // interop with multilangual 
        if ('' == 'true') {
            _containerSelector = 'div.post-container.active'
        } else {
            _containerSelector = 'div.post-container'
        }

        // init
        var P = $(_containerSelector),a,n,t,l,i,c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        // clean
        $(selector).html('')

        // appending
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#"+$(this).prop('id');
            t = $(this).text();
            c = $('<a href="'+i+'" rel="nofollow">'+t+'</a>');
            l = $('<li class="'+n+'_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function(e){
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Hux to support padding
     */
    async("/js/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>



<!-- Multi-Lingual -->




<!-- Image to hack wechat -->
<img src="/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
